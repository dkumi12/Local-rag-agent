# DocuScope AI Configuration
# ===========================

# AI Model Settings
[models]
# Language model for question answering
llm_model = "llama3.2:3b"

# Embedding model for document vectorization
embedding_model = "mxbai-embed-large"

# Number of source documents to retrieve
retrieval_k = 4

# Application Settings
[app]
# Maximum file size in MB
max_file_size = 100

# Temporary file directory
temp_dir = "temp"

# Enable debug logging
debug = false

# Streamlit Settings
[streamlit]
# Default port for web interface
port = 8501

# Theme settings
theme_primary_color = "#B87333"
theme_background_color = "#C6C5C0"
theme_text_color = "#000000"

# Performance Settings
[performance]
# Chunk size for document splitting
chunk_size = 1000

# Chunk overlap for better context
chunk_overlap = 200

# Vector store persist directory
vector_store_dir = "chroma_db"

# Model Settings for Different Hardware
[hardware_profiles]

# For high-end systems
[hardware_profiles.high_performance]
llm_model = "llama3.2:8b"
chunk_size = 2000
retrieval_k = 6

# For standard systems (default)
[hardware_profiles.standard]
llm_model = "llama3.2:3b"
chunk_size = 1000
retrieval_k = 4

# For low-resource systems
[hardware_profiles.low_resource]
llm_model = "llama3.2:1b"
chunk_size = 500
retrieval_k = 2
